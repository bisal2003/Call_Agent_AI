2025-03-23 13:39:11,494 INFO    Thread-3 (process_request_thread):60991 [wandb_setup.py:_flush():67] Current SDK version is 0.19.8
2025-03-23 13:39:11,494 INFO    Thread-3 (process_request_thread):60991 [wandb_setup.py:_flush():67] Configure stats pid to 60991
2025-03-23 13:39:11,494 INFO    Thread-3 (process_request_thread):60991 [wandb_setup.py:_flush():67] Loading settings from /Users/probindhakal/.config/wandb/settings
2025-03-23 13:39:11,494 INFO    Thread-3 (process_request_thread):60991 [wandb_setup.py:_flush():67] Loading settings from /Users/probindhakal/Desktop/NITS_NEURATHON_CALL_AGENT/ai-phone-agent/backend/wandb/settings
2025-03-23 13:39:11,494 INFO    Thread-3 (process_request_thread):60991 [wandb_setup.py:_flush():67] Loading settings from environment variables
2025-03-23 13:39:11,494 INFO    Thread-3 (process_request_thread):60991 [wandb_init.py:setup_run_log_directory():647] Logging user logs to /Users/probindhakal/Desktop/NITS_NEURATHON_CALL_AGENT/ai-phone-agent/backend/wandb/run-20250323_133911-eu1riin3/logs/debug.log
2025-03-23 13:39:11,495 INFO    Thread-3 (process_request_thread):60991 [wandb_init.py:setup_run_log_directory():648] Logging internal logs to /Users/probindhakal/Desktop/NITS_NEURATHON_CALL_AGENT/ai-phone-agent/backend/wandb/run-20250323_133911-eu1riin3/logs/debug-internal.log
2025-03-23 13:39:11,495 INFO    Thread-3 (process_request_thread):60991 [wandb_init.py:init():761] calling init triggers
2025-03-23 13:39:11,495 INFO    Thread-3 (process_request_thread):60991 [wandb_init.py:init():766] wandb.init called with sweep_config: {}
config: {'_wandb': {}}
2025-03-23 13:39:11,495 INFO    Thread-3 (process_request_thread):60991 [wandb_init.py:init():784] starting backend
2025-03-23 13:39:11,495 INFO    Thread-3 (process_request_thread):60991 [wandb_init.py:init():788] sending inform_init request
2025-03-23 13:39:11,522 INFO    Thread-3 (process_request_thread):60991 [backend.py:_multiprocessing_setup():101] multiprocessing start_methods=spawn,fork,forkserver, using: spawn
2025-03-23 13:39:11,523 INFO    Thread-3 (process_request_thread):60991 [wandb_init.py:init():798] backend started and connected
2025-03-23 13:39:11,526 INFO    Thread-3 (process_request_thread):60991 [wandb_init.py:init():891] updated telemetry
2025-03-23 13:39:11,555 INFO    Thread-3 (process_request_thread):60991 [wandb_init.py:init():915] communicating run to backend with 90.0 second timeout
2025-03-23 13:39:12,352 INFO    Thread-3 (process_request_thread):60991 [wandb_init.py:init():990] starting run threads in backend
2025-03-23 13:39:12,418 INFO    Thread-3 (process_request_thread):60991 [wandb_run.py:_console_start():2375] atexit reg
2025-03-23 13:39:12,418 INFO    Thread-3 (process_request_thread):60991 [wandb_run.py:_redirect():2227] redirect: wrap_raw
2025-03-23 13:39:12,418 INFO    Thread-3 (process_request_thread):60991 [wandb_run.py:_redirect():2292] Wrapping output streams.
2025-03-23 13:39:12,418 INFO    Thread-3 (process_request_thread):60991 [wandb_run.py:_redirect():2315] Redirects installed.
2025-03-23 13:39:12,419 INFO    Thread-3 (process_request_thread):60991 [wandb_init.py:init():1032] run started, returning control to user process
2025-03-23 13:39:12,434 INFO    Thread-3 (process_request_thread):60991 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-23 13:39:21,682 INFO    Thread-7 (process_request_thread):60991 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-23 13:39:22,224 INFO    Thread-7 (process_request_thread):60991 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-23 13:39:37,128 INFO    Thread-9 (process_request_thread):60991 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-23 13:39:37,654 INFO    Thread-9 (process_request_thread):60991 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-23 13:39:52,071 INFO    Thread-11 (process_request_thread):60991 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-23 13:39:52,571 INFO    Thread-11 (process_request_thread):60991 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-23 13:40:08,459 INFO    Thread-13 (process_request_thread):60991 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-23 13:40:09,180 INFO    Thread-13 (process_request_thread):60991 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-23 13:40:31,838 INFO    Thread-15 (process_request_thread):60991 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-23 13:40:32,282 INFO    Thread-15 (process_request_thread):60991 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-23 13:40:46,861 INFO    Thread-17 (process_request_thread):60991 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-23 13:40:47,412 INFO    Thread-17 (process_request_thread):60991 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-23 13:41:04,885 INFO    Thread-19 (process_request_thread):60991 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-23 13:41:05,605 INFO    Thread-19 (process_request_thread):60991 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-23 13:41:23,723 INFO    Thread-21 (process_request_thread):60991 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-23 13:41:24,387 INFO    Thread-21 (process_request_thread):60991 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-23 13:41:49,679 INFO    Thread-23 (process_request_thread):60991 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-23 13:41:50,185 INFO    Thread-23 (process_request_thread):60991 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-23 13:42:03,858 INFO    Thread-25 (process_request_thread):60991 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-23 13:42:04,297 INFO    Thread-25 (process_request_thread):60991 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-23 13:42:20,966 INFO    Thread-27 (process_request_thread):60991 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-23 13:42:21,497 INFO    Thread-27 (process_request_thread):60991 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-23 13:42:40,626 INFO    Thread-29 (process_request_thread):60991 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
2025-03-23 13:42:41,233 INFO    Thread-29 (process_request_thread):60991 [wandb_run.py:_config_callback():1261] config_cb None None {'model_name': 'llama-3.3-70b-versatile', 'temperature': 0.9, 'max_tokens': 512, 'max_retries': 2}
